from typing import List, Dict, Any
from app.schemas.report import Report
from app.schemas.paper import PersonalizedPaper
import os
import re
from jinja2 import Environment, FileSystemLoader
from premailer import transform
import cssutils
import logging

# ç¦æ­¢ cssutils è¾“å‡ºä¸æ”¯æŒç°ä»£ CSS å±æ€§çš„è­¦å‘Šæ—¥å¿—
cssutils.log.setLevel(logging.CRITICAL)

class EmailTemplates:
    """
    HTML é‚®ä»¶æ¨¡æ¿ç”Ÿæˆå™¨ (Jinja2 ç‰ˆ)
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. åŠ è½½ Jinja2 æ¨¡æ¿
    2. å‡†å¤‡æ¸²æŸ“æ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®
    3. æ¸²æŸ“ HTML å¹¶ä½¿ç”¨ Premailer å†…è” CSS
    """
    
    # ä¸»é¢˜æ ‡ç­¾æ˜ å°„ï¼ˆå¸¦ emojiï¼‰
    TOPIC_EMOJIS = {
        # 'cs.CV': 'ğŸ–¼ï¸',
        # 'cs.AI': 'ğŸ¤–',
        # 'cs.LG': 'ğŸ§ ',
        # 'cs.CL': 'ğŸ’¬',
        # 'cs.RO': 'ğŸ¦¾',
        # 'cs.NE': 'ğŸŒ',
        'default': ''
    }

    def __init__(self):
        """
        åˆå§‹åŒ–æ¨¡æ¿ç¯å¢ƒ
        """
        template_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'templates')
        self.env = Environment(loader=FileSystemLoader(template_dir))

    def _markdown_to_html(self, text: str) -> str:
        """
        ç®€å•çš„ Markdown è½¬ HTML è½¬æ¢å™¨
        
        Args:
            text (str): Markdown æ–‡æœ¬
            
        Returns:
            str: HTML æ–‡æœ¬
        """
        if not text:
            return ""
            
        # 1. è½¬ä¹‰ HTML (ç®€å•å¤„ç†)
        text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        
        # 2. å¤„ç†æ ‡é¢˜ - ç»Ÿä¸€è½¬æ¢ä¸º h4 ä»¥ä¿æŒæ ·å¼ä¸€è‡´
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
        text = re.sub(r'^#+ (.*?)$', r'<h4>\1</h4>', text, flags=re.MULTILINE)
        
        # 3. å¤„ç†åŠ ç²— **text** -> <strong>text</strong>
        text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
        
        # 4. å¤„ç†å¼•ç”¨ <ref id="xxx"> -> [xxx] (æˆ–è€…é“¾æ¥)
        text = re.sub(r'&lt;ref id="(.*?)"&gt;', r'<a href="https://arxiv.org/abs/\1" style="color: #4f46e5; text-decoration: none;">[\1]</a>', text)
        
        # 5. å¤„ç†æ®µè½
        paragraphs = text.split('\n\n')
        html_parts = []
        for p in paragraphs:
            p = p.strip()
            if not p:
                continue
            if not p.startswith('<h'):
                if p.startswith('- '):
                    items = p.split('\n')
                    list_html = '<ul>'
                    for item in items:
                        if item.strip().startswith('- '):
                            list_html += f'<li>{item.strip()[2:]}</li>'
                    list_html += '</ul>'
                    html_parts.append(list_html)
                else:
                    html_parts.append(f'<p>{p.replace(chr(10), "<br>")}</p>')
            else:
                html_parts.append(p)
                
        return '\n'.join(html_parts)

    def _prepare_paper_data(self, index: int, paper: PersonalizedPaper) -> Dict[str, Any]:
        """
        å‡†å¤‡å•ä¸ªè®ºæ–‡çš„å±•ç¤ºæ•°æ®
        
        Args:
            index (int): åºå·
            paper (PersonalizedPaper): è®ºæ–‡å¯¹è±¡
            
        Returns:
            Dict: æ¨¡æ¿æ‰€éœ€çš„è®ºæ–‡æ•°æ®å­—å…¸
        """
        # è·å–åŸºç¡€æ•°æ®
        title = paper.meta.title if paper.meta else "æœªçŸ¥æ ‡é¢˜"
        authors = ', '.join(paper.meta.authors[:3]) + ('...' if len(paper.meta.authors) > 3 else '') if paper.meta and paper.meta.authors else "æœªçŸ¥ä½œè€…"
        published = paper.meta.published_date if paper.meta else "æœªçŸ¥æ—¥æœŸ"
        
        # å¤„ç†åˆ†ç±»åˆ—è¡¨
        categories = []
        if paper.meta and paper.meta.category:
            for cat in paper.meta.category:
                emoji = self.TOPIC_EMOJIS.get(cat, self.TOPIC_EMOJIS['default'])
                categories.append({"name": cat, "emoji": emoji})
        else:
            categories.append({"name": "æœªåˆ†ç±»", "emoji": self.TOPIC_EMOJIS['default']})

        relevance = round(paper.user_state.relevance_score, 2) if paper.user_state else 0.0
        arxiv_url = paper.meta.links.arxiv if paper.meta and paper.meta.links else "#"
        
        # ç¡®å®šå¾½ç« é¢œè‰²
        if relevance >= 0.8:
            badge_color = '#10b981'  # ç»¿è‰²
        elif relevance >= 0.6:
            badge_color = '#f59e0b'  # é»„è‰²
        else:
            badge_color = '#6b7280'  # ç°è‰²

        # è·å–æ‘˜è¦/ç‚¹è¯„
        tldr = 'æš‚æ— æ‘˜è¦'
        if paper.user_state and paper.user_state.why_this_paper:
            tldr = paper.user_state.why_this_paper
        elif paper.analysis and paper.analysis.tldr:
            tldr = paper.analysis.tldr

        return {
            "index": index,
            "title": title,
            "link": arxiv_url,
            "authors": authors,
            "published": published,
            "categories": categories,
            "relevance": relevance,
            "badge_color": badge_color,
            "tldr": tldr
        }

    def _process_report_content(self, content: str) -> tuple[str, str | None]:
        """
        å¤„ç†æŠ¥å‘Šå†…å®¹ï¼šæå–æ‘˜è¦å¹¶ç§»é™¤å†—ä½™æ ‡é¢˜
        
        Args:
            content (str): åŸå§‹ Markdown å†…å®¹
            
        Returns:
            tuple[str, str | None]: (æ¸…æ´—åçš„å†…å®¹, æå–çš„æ‘˜è¦æ–‡æœ¬)
        """
        if not content:
            return "", None
            
        extracted_summary = None
        cleaned_content = content
        
        # 1. å°è¯•æå– "æ ¸å¿ƒæ‘˜è¦"
        # åŒ¹é… ## æ ¸å¿ƒæ‘˜è¦ [å†…å®¹] ## è¯¦ç»†å†…å®¹ (æˆ–ç»“å°¾)
        summary_match = re.search(r'##\s*æ ¸å¿ƒæ‘˜è¦\s*\n(.*?)(?=\n##|\Z)', content, re.DOTALL)
        if summary_match:
            extracted_summary = summary_match.group(1).strip()
            # ä»å†…å®¹ä¸­ç§»é™¤æ ¸å¿ƒæ‘˜è¦éƒ¨åˆ†
            cleaned_content = cleaned_content.replace(summary_match.group(0), "")
            
        # 2. ç§»é™¤ "è¯¦ç»†å†…å®¹" æ ‡é¢˜åŠå¯èƒ½çš„æ®‹ç•™å­—ç¬¦
        # ç§»é™¤ "## è¯¦ç»†å†…å®¹"
        cleaned_content = re.sub(r'##\s*è¯¦ç»†å†…å®¹\s*\n', '', cleaned_content)
        # ç§»é™¤å¯èƒ½æ®‹ç•™çš„å­¤ç«‹ # ç¬¦å· (ç”¨æˆ·åé¦ˆå‡ºç°çš„æƒ…å†µ)
        cleaned_content = re.sub(r'^\s*#\s*\n', '', cleaned_content, flags=re.MULTILINE)
        
        return cleaned_content.strip(), extracted_summary

    def _markdown_to_html(self, text: str) -> str:
        """
        Markdown è½¬ HTML è½¬æ¢å™¨ï¼ˆå¸¦è‡ªåŠ¨ç¼–å·ï¼‰
        
        Args:
            text (str): Markdown æ–‡æœ¬
            
        Returns:
            str: HTML æ–‡æœ¬
        """
        if not text:
            return ""
            
        # 1. è½¬ä¹‰ HTML
        text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        
        # 2. è‡ªåŠ¨ç¼–å·ä¸æ ‡é¢˜å¤„ç†
        # æŸ¥æ‰¾æ‰€æœ‰æ ‡é¢˜ (###, ####, #####) å¹¶æ·»åŠ åºå·
        header_counter = 0
        
        def header_replace(match):
            nonlocal header_counter
            level = len(match.group(1)) # æ ‡é¢˜çº§åˆ« (### = 3)
            title = match.group(2)
            
            # åªå¯¹ä¸»è¦çš„å°æ ‡é¢˜è¿›è¡Œç¼–å· (é€šå¸¸æ˜¯ h3 æˆ– h4)
            # å‡è®¾æ­£æ–‡ä¸­çš„ä¸»è¦åˆ†æ®µæ˜¯ ### æˆ– ####
            header_counter += 1
            
            # æ˜ å°„ Markdown çº§åˆ«åˆ° HTML æ ‡ç­¾
            # å¼ºåˆ¶ç»Ÿä¸€ä½¿ç”¨ h4 ä»¥ä¿æŒæ ·å¼ä¸€è‡´
            tag = 'h4'
            
            # æ·»åŠ åºå·æ ·å¼
            numbered_title = f'<span style="background-color: #f1f5f9; color: #64748b; padding: 2px 8px; border-radius: 4px; font-size: 0.8em; margin-right: 8px; vertical-align: middle;">{header_counter}</span>{title}'
            
            return f'<{tag}>{numbered_title}</{tag}>'

        # åŒ¹é… ^(#{3,5}) (å†…å®¹)
        text = re.sub(r'^(#{3,5})\s+(.*?)$', header_replace, text, flags=re.MULTILINE)
        
        # å¤„ç† ## (å¦‚æœæœ‰å‰©ä½™çš„äºŒçº§æ ‡é¢˜ï¼Œè½¬ä¸º h2ï¼Œä¸ç¼–å·)
        text = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', text, flags=re.MULTILINE)
        
        # 3. å¤„ç†åŠ ç²— **text** -> <strong>text</strong>
        text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
        
        # 4. å¤„ç†å¼•ç”¨ <ref id="xxx"> -> [xxx]
        text = re.sub(r'&lt;ref id="(.*?)"&gt;', r'<a href="https://arxiv.org/abs/\1" style="color: #4f46e5; text-decoration: none;">[\1]</a>', text)
        
        # 5. å¤„ç†æ®µè½å’Œåˆ—è¡¨
        paragraphs = text.split('\n\n')
        html_parts = []
        for p in paragraphs:
            p = p.strip()
            if not p:
                continue
            if not p.startswith('<h'):
                if p.startswith('- '):
                    items = p.split('\n')
                    list_html = '<ul>'
                    for item in items:
                        if item.strip().startswith('- '):
                            list_html += f'<li>{item.strip()[2:]}</li>'
                    list_html += '</ul>'
                    html_parts.append(list_html)
                else:
                    html_parts.append(f'<p>{p.replace(chr(10), "<br>")}</p>')
            else:
                html_parts.append(p)
                
        return '\n'.join(html_parts)

    def generate_email_html(self, report: Report, papers: List[PersonalizedPaper], stats: Dict) -> str:
        """
        ç”Ÿæˆå®Œæ•´é‚®ä»¶ HTML
        
        Args:
            report (Report): æŠ¥å‘Šå¯¹è±¡
            papers (List[PersonalizedPaper]): è®ºæ–‡åˆ—è¡¨
            stats (Dict): ç»Ÿè®¡æ•°æ®
            
        Returns:
            str: å¤„ç†åçš„å®Œæ•´ HTML å†…å®¹ (Processed complete HTML content)
        """
        # 1. å‡†å¤‡åŸºç¡€ä¸Šä¸‹æ–‡
        frontend_url = os.getenv('FRONTEND_URL', 'http://localhost:5173')
        
        # 2. å‡†å¤‡ä¸»é¢˜åˆ—è¡¨æ•°æ®
        category_list = []
        for cat, count in list(stats.get('category_stats', {}).items())[:5]:
            emoji = self.TOPIC_EMOJIS.get(cat, self.TOPIC_EMOJIS['default'])
            category_list.append((cat, count, emoji))
            
        # 3. å‡†å¤‡è®ºæ–‡åˆ—è¡¨æ•°æ®
        papers_data = []
        for idx, paper in enumerate(papers[:15], 1):
            papers_data.append(self._prepare_paper_data(idx, paper))

        # 4. å¤„ç†æŠ¥å‘Šå†…å®¹
        cleaned_content, extracted_summary = self._process_report_content(report.content)
        
        # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„æ‘˜è¦
        final_summary = extracted_summary if extracted_summary else report.summary

        # 5. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        context = {
            "title": report.title,
            "date": report.date,
            "summary": final_summary,
            "content_html": self._markdown_to_html(cleaned_content),
            "stats": {
                "total_papers": stats.get('total_papers', 0),
                "recommended_papers": stats.get('recommended_papers', 0),
                "avg_relevance_score": stats.get('avg_relevance_score', 0.0),
                "category_list": category_list,
                "generated_at": stats.get('generated_at', '') # [NEW] ä¼ é€’ç”Ÿæˆæ—¶é—´
            },
            "papers": papers_data,
            "highlight": None,
            "frontend_url": frontend_url,
            "report_id": report.id,
            "user_id": report.user_id,
            "backend_url": os.getenv('BACKEND_URL', 'http://localhost:8000')
        }

        # 6. æ¸²æŸ“æ¨¡æ¿
        template = self.env.get_template('daily_report.html')
        html_content = template.render(**context)
        
        # 7. å†…è” CSS
        final_html = transform(html_content)
        
        return final_html
