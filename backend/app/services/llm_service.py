import os
import json
from typing import Dict, Any, Optional
from openai import OpenAI
from app.core.config import settings

class QwenService:
    def __init__(self):
        """
        åˆå§‹åŒ– QwenService æœåŠ¡ã€‚
        
        åŠŸèƒ½ï¼š
            ä»é…ç½®ä¸­åŠ è½½ LLM è®¾ç½®ï¼Œåˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ã€‚
            æ”¯æŒåŠ¨æ€åˆ‡æ¢ API æº (OpenRouter, DashScope, Bohrium)ã€‚
        """
        try:
            config = settings.get_llm_config()
            self.client = OpenAI(
                api_key=config["api_key"],
                base_url=config["base_url"]
            )
            self.model = config["model"]
            self.provider = settings.LLM_PROVIDER
            
            if self.provider == "bohrium":
                print(f"âœ“ LLM Service initialized with Bohrium (Model: {self.model})")
            else:
                print(f"âœ“ LLM æœåŠ¡åˆå§‹åŒ–æˆåŠŸ | æº: {self.provider} | æ¨¡å‹: {self.model}")
        except Exception as e:
            print(f"âœ— LLM æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
            self.model = ""

    def read_prompt(self, filename: str) -> str:
        """
        ä»æ–‡ä»¶ç³»ç»Ÿä¸­è¯»å–æç¤ºè¯æ¨¡æ¿ã€‚

        Args:
            filename (str): æç¤ºè¯æ¨¡æ¿çš„æ–‡ä»¶å (ä¾‹å¦‚ "filter.md")ã€‚

        Returns:
            str: æç¤ºè¯æ¨¡æ¿çš„å†…å®¹ã€‚
        """
        # backend/services/llm_service.py -> backend/prompt
        path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "prompt", filename)
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    def call_llm(self, prompt: str, model: str = None, response_format: Optional[Dict[str, Any]] = {"type": "json_object"}) -> tuple[str, Dict[str, Any]]:
        """
        è°ƒç”¨ LLM API æ‰§è¡Œè¯·æ±‚ (åŒ…å«é‡è¯•æœºåˆ¶)ã€‚
        æ”¯æŒåŠ¨æ€åˆ‡æ¢æ¨¡å‹ï¼Œå¹¶è§£æ OpenRouter çš„æˆæœ¬ä¸ç¼“å­˜ä¿¡æ¯ã€‚

        Args:
            prompt (str): å‘é€ç»™ LLM çš„å®Œæ•´æç¤ºè¯å­—ç¬¦ä¸²ã€‚
            model (str, optional): æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ã€‚å¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤é…ç½®çš„æ¨¡å‹ã€‚
            response_format (Dict[str, Any], optional): API è¿”å›æ ¼å¼é…ç½®ã€‚é»˜è®¤ä¸º {"type": "json_object"}ã€‚

        Returns:
            tuple[str, Dict[str, Any]]: (å†…å®¹å­—ç¬¦ä¸², ä½¿ç”¨ç»Ÿè®¡å­—å…¸)ã€‚
                                        ç»Ÿè®¡å­—å…¸åŒ…å«:
                                        - 'prompt_tokens': è¾“å…¥ Token æ•°
                                        - 'completion_tokens': è¾“å‡º Token æ•°
                                        - 'total_tokens': æ€» Token æ•°
                                        - 'cost': é¢„ä¼°æˆ–å®é™…æˆæœ¬ (USD)
                                        - 'cache_hit_tokens': ç¼“å­˜å‘½ä¸­çš„ Token æ•°
                                        - 'model': å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
                                        å¦‚æœè°ƒç”¨å¤±è´¥ï¼Œè¿”å› ("{}", {})ã€‚
        """
        import time
        import traceback
        
        if not self.client:
            print("âœ— LLM å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œè¯·æ±‚")
            return "{}", {}

        # ä½¿ç”¨æŒ‡å®šæ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
        target_model = model if model else self.model
        
        max_retries = 3
        base_delay = 2
        
        for attempt in range(max_retries + 1):
            try:
                completion = self.client.chat.completions.create(
                    model=target_model,
                    messages=[
                        {"role": "system", "content": self.read_prompt("system.md")},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=1.2,
                    response_format=response_format # ä½¿ç”¨ä¼ å…¥çš„æ ¼å¼é…ç½®
                )
                response = completion.choices[0].message.content
                
                # ========== è§£æ Usage ç»Ÿè®¡ä¿¡æ¯ ==========
                usage = completion.usage
                usage_dict = {
                    "prompt_tokens": usage.prompt_tokens if usage else 0,
                    "completion_tokens": usage.completion_tokens if usage else 0,
                    "total_tokens": usage.total_tokens if usage else 0,
                    "model": target_model,
                    "cache_hit_tokens": 0,  # åˆå§‹åŒ–ç¼“å­˜å‘½ä¸­tokenæ•°
                    "cost": 0.0  # åˆå§‹åŒ–æˆæœ¬
                }

                # ========== Providerç‰¹å®šå­—æ®µè§£æ ==========
                # æŸäº›Providerï¼ˆå¦‚OpenRouterï¼‰ä¼šè¿”å›é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
                if self.provider == "openrouter":
                    # OpenRouter æ”¯æŒç¼“å­˜å‘½ä¸­ç»Ÿè®¡
                    if usage and hasattr(usage, 'prompt_tokens_details') and usage.prompt_tokens_details:
                        details = usage.prompt_tokens_details
                        if isinstance(details, dict):
                            usage_dict["cache_hit_tokens"] = details.get("cached_tokens", 0)
                        elif hasattr(details, 'cached_tokens'):
                            usage_dict["cache_hit_tokens"] = details.cached_tokens
                    
                    # OpenRouter å¯èƒ½åœ¨å“åº”ä¸­ç›´æ¥è¿”å›æˆæœ¬ä¿¡æ¯
                    if hasattr(completion, 'usage') and isinstance(completion.usage, dict):
                        usage_dict["cost"] = completion.usage.get("cost", 0.0)
                    elif hasattr(completion, 'model_extra') and completion.model_extra:
                        usage_info = completion.model_extra.get('usage', {})
                        if isinstance(usage_info, dict):
                            usage_dict["cost"] = usage_info.get('cost', 0.0)
                elif self.provider == "bohrium":
                    # Bohrium API ä¹Ÿæ”¯æŒç¼“å­˜å‘½ä¸­ç»Ÿè®¡
                    if usage and hasattr(usage, 'prompt_tokens_details') and usage.prompt_tokens_details:
                        details = usage.prompt_tokens_details
                        if isinstance(details, dict):
                            usage_dict["cache_hit_tokens"] = details.get("cached_tokens", 0)
                        elif hasattr(details, 'cached_tokens'):
                            usage_dict["cache_hit_tokens"] = details.cached_tokens

                # ========== é€šç”¨æˆæœ¬è®¡ç®— ==========
                # å½“APIä¸è¿”å›æˆæœ¬æ—¶ï¼Œæ ¹æ®tokenæ•°é‡å’Œé…ç½®çš„ä»·æ ¼è‡ªåŠ¨è®¡ç®—
                if usage_dict["cost"] == 0.0 and usage_dict["total_tokens"] > 0:
                    from app.core.config import settings
                    
                    # ä»é…ç½®è·å–è¯¥æ¨¡å‹çš„å®šä»·
                    pricing = settings.get_model_pricing(target_model)
                    
                    # è®¡ç®—æˆæœ¬ (USD)
                    # å…¬å¼ï¼šæˆæœ¬ = (è¾“å…¥tokens / 1,000,000) Ã— è¾“å…¥ä»·æ ¼ + (è¾“å‡ºtokens / 1,000,000) Ã— è¾“å‡ºä»·æ ¼
                    input_cost = (usage_dict["prompt_tokens"] / 1_000_000) * pricing["input_price"]
                    output_cost = (usage_dict["completion_tokens"] / 1_000_000) * pricing["output_price"]
                    usage_dict["cost"] = input_cost + output_cost
                    
                    print(f"[æˆæœ¬è®¡ç®—] æ¨¡å‹: {target_model} | "
                          f"è¾“å…¥: {usage_dict['prompt_tokens']} tokens (${input_cost:.6f}) | "
                          f"è¾“å‡º: {usage_dict['completion_tokens']} tokens (${output_cost:.6f}) | "
                          f"æ€»è®¡: ${usage_dict['cost']:.6f}")

                
                # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
                response = response.strip()
                if response.startswith("```"):
                    lines = response.split('\n')
                    if lines[0].startswith("```"):
                        lines = lines[1:]
                    if lines and lines[-1].strip() == "```":
                        lines = lines[:-1]
                    response = '\n'.join(lines)
                
                return response.strip(), usage_dict
                
            except Exception as e:
                error_str = str(e)
                import traceback
                traceback_str = traceback.format_exc()
                
                if "429" in error_str or "Rate limit" in error_str:
                    if attempt < max_retries:
                        delay = base_delay * (2 ** attempt)
                        print(f"âš ï¸ LLM é€Ÿç‡é™åˆ¶ (429), {delay}ç§’åé‡è¯•... ({attempt + 1}/{max_retries})")
                        time.sleep(delay)
                        continue
                
                print(f"âŒ LLM è°ƒç”¨é”™è¯¯: {e}")
                print(f"ğŸ” é”™è¯¯å †æ ˆ: {traceback_str}")
                # é 429 é”™è¯¯æˆ–é‡è¯•è€—å°½ï¼Œè¿”å›ç©º
                return "{}", {}
                
        return "{}", {}

    def filter_paper(self, paper: Dict, user_profile: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æ£€æŸ¥è®ºæ–‡æ˜¯å¦ä¸ç”¨æˆ·ç”»åƒç›¸å…³ã€‚
        
        åŠŸèƒ½è¯´æ˜ï¼š
            è°ƒç”¨LLMå¯¹è®ºæ–‡è¿›è¡Œç›¸å…³æ€§è¯„ä¼°ï¼Œåˆ¤æ–­è®ºæ–‡æ˜¯å¦ç¬¦åˆç”¨æˆ·çš„ç ”ç©¶å…´è¶£ã€‚
            ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹ä»¥é™ä½æˆæœ¬ã€‚

        Args:
            paper (Dict): è®ºæ–‡å…ƒæ•°æ®å­—å…¸ï¼ŒåŒ…å«titleã€abstractã€categoryç­‰å­—æ®µ
            user_profile (str): ç”¨æˆ·ç”»åƒå­—ç¬¦ä¸²ï¼Œæè¿°ç”¨æˆ·çš„ç ”ç©¶æ–¹å‘å’Œå…´è¶£

        Returns:
            Dict[str, Any]: ç­›é€‰ç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - is_relevant (bool): æ˜¯å¦ç›¸å…³
                - score (int): ç›¸å…³æ€§è¯„åˆ† (0-10)
                - reason (str): åˆ¤æ–­ç†ç”±
                - _usage (dict): APIè°ƒç”¨ç»Ÿè®¡ä¿¡æ¯
        """
        template = self.read_prompt("filter.md")
        prompt = template.format(
            user_profile=user_profile,
            title=paper.get("title", ""),
            abstract=paper.get("abstract", ""),
            category=paper.get("category", "")
        )
        
        # ä½¿ç”¨é€šç”¨çš„ä¾¿å®œæ¨¡å‹é…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨æ–°é…ç½®ï¼Œå›é€€åˆ°æ—§é…ç½®ä»¥ä¿æŒå…¼å®¹
        cheap_model = getattr(settings, 'MODEL_CHEAP', settings.OPENROUTER_MODEL_CHEAP)
        response, usage = self.call_llm(prompt, model=cheap_model)
        try:
            result = json.loads(response)
            result["_usage"] = usage  # æ³¨å…¥ usage ç»Ÿè®¡ä¿¡æ¯
            return result
        except json.JSONDecodeError:
            print(f"[é”™è¯¯] filter_paper è§£æ JSON å¤±è´¥: {response[:100]}...")
            return {"is_relevant": False, "score": 0, "reason": "JSONè§£æé”™è¯¯", "_usage": usage}

    def analyze_paper(self, abstract: str, comment: str = "") -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM åˆ†æè®ºæ–‡è¯¦æƒ…ã€‚
        
        åŠŸèƒ½è¯´æ˜ï¼š
            å¯¹è®ºæ–‡æ‘˜è¦è¿›è¡Œæ·±åº¦åˆ†æï¼Œæå–å…³é”®ä¿¡æ¯ã€åˆ›æ–°ç‚¹ã€æ–¹æ³•ç­‰ã€‚
            ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹ä»¥æ§åˆ¶æˆæœ¬ã€‚

        Args:
            abstract (str): è®ºæ–‡æ‘˜è¦æ–‡æœ¬
            comment (str, optional): è®ºæ–‡çš„é¢å¤–å¤‡æ³¨ä¿¡æ¯ã€‚é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ã€‚

        Returns:
            Dict[str, Any]: åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
                - å„ç§åˆ†æå­—æ®µï¼ˆå…·ä½“å–å†³äºanalyze.mdæ¨¡æ¿çš„å®šä¹‰ï¼‰
                - _usage (dict): APIè°ƒç”¨ç»Ÿè®¡ä¿¡æ¯
        """
        template = self.read_prompt("analyze.md")
        
        prompt = template.format(
            abstract=abstract,
            comment=comment
        )
        
        # ä½¿ç”¨é€šç”¨çš„ä¾¿å®œæ¨¡å‹é…ç½®
        cheap_model = getattr(settings, 'MODEL_CHEAP', settings.OPENROUTER_MODEL_CHEAP)
        response, usage = self.call_llm(prompt, model=cheap_model)
        try:
            result = json.loads(response)
            result["_usage"] = usage
            return result
        except json.JSONDecodeError:
            print(f"[é”™è¯¯] analyze_paper è§£æ JSON å¤±è´¥: {response[:100]}...")
            return {"_usage": usage}

    def generate_report(self, papers: list, user_profile: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆæ¯æ—¥æŠ¥å‘Šã€‚

        Args:
            papers (list): è®ºæ–‡åˆ—è¡¨ã€‚
            user_profile (str): ç”¨æˆ·ç”»åƒå­—ç¬¦ä¸²ã€‚

        Returns:
            Dict[str, Any]: æŠ¥å‘Šç”Ÿæˆç»“æœ (åŒ…å« _usage)ã€‚
        """
        template = self.read_prompt("report.md")
        
        # ä¸ºæç¤ºè¯æ ¼å¼åŒ–è®ºæ–‡åˆ—è¡¨
        papers_text = ""
        for p in papers:
            papers_text += f"ID: {p['id']}\nTitle: {p['title']}\nAbstract: {p['abstract'][:200]}...\n\n"
            
        # ä½¿ç”¨ replace æ›¿ä»£ formatï¼Œé¿å… JSON å¤§æ‹¬å·å†²çª
        from datetime import datetime
        import time
        import re
        
        current_date = datetime.now().strftime("%Y/%m/%d")
        prompt = template.replace("{user_profile}", user_profile).replace("{papers}", papers_text).replace("{date}", current_date)
        
        # å®šä¹‰è§£æè¾…åŠ©å‡½æ•°
        def _parse_report_response(response_text: str) -> Optional[Dict[str, Any]]:
            """
            è§£æ LLM è¿”å›çš„ XML æ ‡ç­¾æ ¼å¼æŠ¥å‘Šã€‚
            
            Args:
                response_text (str): LLM è¿”å›çš„åŸå§‹æ–‡æœ¬ã€‚
                
            Returns:
                Optional[Dict[str, Any]]: è§£æåçš„å­—å…¸ï¼ŒåŒ…å« title, summary, contentã€‚è§£æå¤±è´¥è¿”å› Noneã€‚
            """
            try:
                # ä½¿ç”¨éè´ªå©ªåŒ¹é…æå–æ ‡ç­¾å†…å®¹ï¼Œre.DOTALL å…è®¸åŒ¹é…æ¢è¡Œç¬¦
                title_match = re.search(r'<title>(.*?)</title>', response_text, re.DOTALL)
                summary_match = re.search(r'<summary>(.*?)</summary>', response_text, re.DOTALL)
                content_match = re.search(r'<content>(.*?)</content>', response_text, re.DOTALL)
                
                if not (title_match and summary_match and content_match):
                    print(f"âŒ Report parsing failed. Missing tags. Response preview: {response_text[:200]}...")
                    return None
                
                return {
                    "title": title_match.group(1).strip(),
                    "summary": summary_match.group(1).strip(),
                    "content": content_match.group(1).strip()
                }
            except Exception as e:
                print(f"âŒ Report parsing exception: {e}")
                return None

        # å®šä¹‰é‡è¯•é€»è¾‘
        def try_generate(model_name, retries=3):
            """
            å°è¯•ä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”ŸæˆæŠ¥å‘Šã€‚
            
            Args:
                model_name (str): æ¨¡å‹åç§°ã€‚
                retries (int): é‡è¯•æ¬¡æ•°ã€‚
                
            Returns:
                Optional[Dict[str, Any]]: ç”Ÿæˆå¹¶è§£æåçš„ç»“æœå­—å…¸ã€‚
            """
            for i in range(retries):
                print(f"Generating report with {model_name} (Attempt {i+1}/{retries})...")
                # ç§»é™¤ response_format={"type": "json_object"}ï¼Œå…è®¸è‡ªç”±æ ¼å¼è¾“å‡º
                # æ˜¾å¼ä¼ å…¥ None ä»¥è¦†ç›–é»˜è®¤çš„ JSON æ¨¡å¼
                response, usage = self.call_llm(prompt, model=model_name, response_format=None)
                
                if usage and response and response != "{}":
                    parsed_result = _parse_report_response(response)
                    if parsed_result:
                        parsed_result["_usage"] = usage
                        return parsed_result
                
                if i < retries - 1:
                    time.sleep(2) # é‡è¯•é—´éš”
            return None

        # 1. å°è¯•ä¸»æ¨¡å‹ï¼ˆä½¿ç”¨é€šç”¨é…ç½®ï¼‰
        performance_model = getattr(settings, 'MODEL_PERFORMANCE', settings.OPENROUTER_MODEL_PERFORMANCE)
        result = try_generate(performance_model, retries=3)
        
        # 2. å¦‚æœä¸»æ¨¡å‹å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ¨¡å‹
        if not result:
            print(f"âš ï¸ ä¸»æ¨¡å‹ {performance_model} åœ¨3æ¬¡å°è¯•åå¤±è´¥ã€‚åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹...")
            fallback_model = "deepseek/deepseek-v3.2"
            result = try_generate(fallback_model, retries=3)
            
        if result:
            # è‡ªåŠ¨å¡«å…… ref_papers (ç›´æ¥ä½¿ç”¨è¾“å…¥çš„è®ºæ–‡åˆ—è¡¨ ID)
            result["ref_papers"] = [p['id'] for p in papers]
            # å†æ¬¡ç¡®è®¤ fallback æ¨¡å‹æˆåŠŸæ—¥å¿—
            if result.get("_usage", {}).get("model") == "deepseek/deepseek-v3.2":
                 print(f"âœ“ Report generated successfully with fallback model deepseek/deepseek-v3.2")
            return result
            
        print("âŒ All report generation attempts failed.")
        return {"_usage": {}} # è¿”å›ç©º usage è¡¨ç¤ºå½»åº•å¤±è´¥

    def extract_categories(self, text: str) -> Dict[str, Any]:
        """
        ä»è‡ªç„¶è¯­è¨€ä¸­æå– Arxiv ç±»åˆ«å’Œä½œè€…ã€‚
        
        åŠŸèƒ½è¯´æ˜ï¼š
            è§£æç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæå–å…¶ä¸­æåˆ°çš„Arxivåˆ†ç±»å’Œä½œè€…åç§°ã€‚
            ç”¨äºæ‰‹åŠ¨æŸ¥è¯¢åŠŸèƒ½ï¼Œå°†ç”¨æˆ·è¾“å…¥è½¬åŒ–ä¸ºç»“æ„åŒ–çš„æŸ¥è¯¢å‚æ•°ã€‚

        Args:
            text (str): ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬

        Returns:
            Dict[str, Any]: æå–ç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                - categories (list): æå–å‡ºçš„ Arxiv ç±»åˆ«åˆ—è¡¨ï¼ˆå¦‚ ["cs.CV", "cs.AI"]ï¼‰
                - authors (list): æå–å‡ºçš„ä½œè€…åˆ—è¡¨
                - _usage (dict): APIè°ƒç”¨ç»Ÿè®¡ä¿¡æ¯
        """
        template = self.read_prompt("extract_categories.md")
        prompt = template.replace("{user_input}", text)
        
        # ä½¿ç”¨é€šç”¨çš„ä¾¿å®œæ¨¡å‹é…ç½®
        cheap_model = getattr(settings, 'MODEL_CHEAP', settings.OPENROUTER_MODEL_CHEAP)
        response, usage = self.call_llm(prompt, model=cheap_model)
        try:
            result = json.loads(response)
            result["_usage"] = usage
            return result
        except json.JSONDecodeError:
            print(f"[é”™è¯¯] extract_categories è§£æ JSON å¤±è´¥: {response[:100]}...")
            # Fallback: å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return {"categories": [], "authors": [], "_usage": usage}

llm_service = QwenService()
