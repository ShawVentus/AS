"""
workflow_engine.py
å·¥ä½œæµå¼•æ“æ ¸å¿ƒæœåŠ¡ã€‚

è´Ÿè´£ç®¡ç†å·¥ä½œæµçš„æ‰§è¡Œã€çŠ¶æ€è¿½è¸ªã€é‡è¯•æœºåˆ¶å’Œå®æ—¶ç›‘æ§ã€‚
"""

import os
import time
import json
import traceback
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from uuid import uuid4

from app.core.database import get_db
# from app.services.email_service import email_service # TODO: åˆ›å»º email_service æ¨¡å—
from app.core.workflow_step import WorkflowStep
from app.core.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class WorkflowEngine:
    """
    å·¥ä½œæµå¼•æ“ã€‚
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å·¥ä½œæµç”Ÿå‘½å‘¨æœŸï¼ˆåˆ›å»ºã€æ‰§è¡Œã€æš‚åœã€æ¢å¤ï¼‰
    2. çŠ¶æ€è¿½è¸ªä¸æŒä¹…åŒ–ï¼ˆæ•°æ®åº“ï¼‰
    3. å¤±è´¥é‡è¯•ä¸é”™è¯¯å¤„ç†
    4. Token æ¶ˆè€—ä¸æˆæœ¬è®¡ç®—
    5. å®æ—¶è¿›åº¦ç›‘æ§
    """
    
    def __init__(self, execution_id: Optional[str] = None):
        self.db = get_db()
        self.steps: List[WorkflowStep] = []
        self.context: Dict[str, Any] = {}
        self.execution_id: Optional[str] = execution_id
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.admin_emails = os.environ.get("ADMIN_EMAILS", "").split(",")
        self.llm_price_input = float(os.environ.get("LLM_PRICE_INPUT", "1.0"))  # USD per 1M tokens
        self.llm_price_input = float(os.environ.get("LLM_PRICE_INPUT", "1.0"))  # USD per 1M tokens
        self.llm_price_output = float(os.environ.get("LLM_PRICE_OUTPUT", "5.0"))

    def _setup_logging(self, execution_id: str):
        """è®¾ç½®æ–‡ä»¶æ—¥å¿—"""
        log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "logs")
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
            
        log_file = os.path.join(log_dir, f"workflow_{execution_id}.log")
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        
        # æ·»åŠ åˆ° root logger æˆ–å½“å‰ logger
        logger.addHandler(file_handler)
        
        # [Fix] ç¦æ­¢ httpx è¾“å‡º INFO æ—¥å¿— (å¦‚ 200 OK)
        logging.getLogger("httpx").setLevel(logging.WARNING)
        
        logger.info(f"ğŸ“‚ æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {log_file}")
        return file_handler
    
    def register_step(self, step: WorkflowStep):
        """æ³¨å†Œå·¥ä½œæµæ­¥éª¤"""
        self.steps.append(step)
        logger.info(f"ğŸ“ æ³¨å†Œæ­¥éª¤: [{step.name}]")

    def create_execution(self, workflow_type: str, initial_context: Dict[str, Any] = None) -> str:
        """
        åˆ›å»ºä¸€ä¸ªæ–°çš„æ‰§è¡Œè®°å½•ï¼Œä½†ä¸ç«‹å³æ‰§è¡Œã€‚
        ç”¨äºå¼‚æ­¥ä»»åŠ¡åœºæ™¯ï¼Œå…ˆè¿”å› ID ç»™å‰ç«¯ã€‚
        """
        self.context = initial_context or {}
        self.execution_id = self._create_execution_record(workflow_type)
        logger.info(f"ğŸ†• åˆ›å»ºæ‰§è¡Œè®°å½•: {workflow_type} (ID: {self.execution_id})")
        return self.execution_id
    
    def execute_workflow(self, workflow_type: str, initial_context: Dict[str, Any] = None):
        """
        æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµã€‚
        
        Args:
            workflow_type (str): å·¥ä½œæµç±»å‹ï¼Œå¦‚ 'daily_update'
            initial_context (Dict[str, Any], optional): åˆå§‹ä¸Šä¸‹æ–‡
        """
        self.context = initial_context or {}
        
        # 1. åˆ›å»ºæ‰§è¡Œè®°å½• (å¦‚æœå°šæœªå­˜åœ¨)
        if not self.execution_id:
            self.execution_id = self._create_execution_record(workflow_type)
        else:
            # å¦‚æœå·²å­˜åœ¨ ID (ä¾‹å¦‚ç”± API é¢„å…ˆåˆ›å»º)ï¼Œåˆ™æ›´æ–°çŠ¶æ€ä¸º running
            self._update_execution_status("running")
            
        # è®¾ç½®æ—¥å¿—
        log_handler = self._setup_logging(self.execution_id)
            
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow_type} (ID: {self.execution_id})")
        
        # 2. åˆå§‹åŒ–æ­¥éª¤è®°å½•
        for i, step in enumerate(self.steps):
            self._create_step_record(step, i)
        
        # 3. é¡ºåºæ‰§è¡Œæ­¥éª¤
        try:
            for i, step in enumerate(self.steps):
                # æ£€æŸ¥ should_stop æ ‡å¿—
                # ç”¨äºå¤„ç†å·¥ä½œæµæå‰ç»ˆæ­¢çš„æƒ…å†µï¼ˆå¦‚æ‰‹åŠ¨æŸ¥è¯¢æ— ç»“æœï¼‰
                if self.context.get("should_stop", False):
                    # [é‡æ„] è°ƒç”¨ç»Ÿä¸€çš„å¤„ç†æ–¹æ³•
                    self._handle_should_stop()
                    return self.execution_id
                
                self._execute_step_with_retry(step, i)
            
            # æ‰€æœ‰æ­¥éª¤å®Œæˆ
            self._update_execution_status("completed", completed_at=datetime.now().isoformat())

            logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {self.execution_id}")
            
            # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            self.generate_summary_report()
            
            # ç§»é™¤æ—¥å¿— handler
            if log_handler:
                logger.removeHandler(log_handler)
                log_handler.close()
            
        except Exception as e:
            # å·¥ä½œæµå¤±è´¥
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            self._update_execution_status("failed", error=str(e))
            self._send_failure_alert(workflow_type, str(e), traceback.format_exc())
            raise e
        
        return self.execution_id
    
    def resume_workflow(self, execution_id: str):
        """
        ä»æ–­ç‚¹æ¢å¤å·¥ä½œæµã€‚
        
        Args:
            execution_id (str): æ‰§è¡Œè®°å½• ID
        """
        self.execution_id = execution_id
        logger.info(f"ğŸ”„ æ¢å¤å·¥ä½œæµ: {execution_id}")
        
        # 1. åŠ è½½æ‰§è¡Œè®°å½•
        exec_response = self.db.table("workflow_executions").select("*").eq("id", execution_id).execute()
        if not exec_response.data:
            raise ValueError(f"æ‰¾ä¸åˆ°æ‰§è¡Œè®°å½•: {execution_id}")
        
        exec_data = exec_response.data[0]
        workflow_type = exec_data["workflow_type"]
        self.context = json.loads(exec_data.get("metadata", "{}"))
        
        # 2. åŠ è½½æ­¥éª¤è®°å½•ï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ªå¤±è´¥æˆ–æœªå®Œæˆçš„æ­¥éª¤
        steps_response = self.db.table("workflow_steps") \
            .select("*") \
            .eq("execution_id", execution_id) \
            .order("step_order") \
            .execute()
        
        step_records = steps_response.data
        
        # 3. é‡æ–°æ³¨å†Œæ­¥éª¤ (éœ€è¦æ ¹æ® workflow_type é‡æ–°æ„é€ )
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾æ˜¯ daily_update å·¥ä½œæµ
        if workflow_type == "daily_update":
            from app.services.workflow_steps.check_update_step import CheckUpdateStep
            from app.services.workflow_steps.clear_daily_step import ClearDailyStep
            from app.services.workflow_steps.run_crawler_step import RunCrawlerStep
            from app.services.workflow_steps.fetch_details_step import FetchDetailsStep
            from app.services.workflow_steps.analyze_public_step import AnalyzePublicStep
            from app.services.workflow_steps.archive_step import ArchiveStep
            from app.services.workflow_steps.personalized_filter_step import PersonalizedFilterStep
            from app.services.workflow_steps.generate_report_step import GenerateReportStep
            
            self.register_step(CheckUpdateStep())
            self.register_step(ClearDailyStep())
            self.register_step(RunCrawlerStep())
            self.register_step(FetchDetailsStep())
            self.register_step(AnalyzePublicStep())
            self.register_step(ArchiveStep())
            self.register_step(PersonalizedFilterStep())
            self.register_step(GenerateReportStep())
        
        # 4. æ‰¾åˆ°éœ€è¦é‡æ–°æ‰§è¡Œçš„æ­¥éª¤
        resume_from_index = 0
        for record in step_records:
            if record["status"] not in ["completed", "skipped"]:
                break
            resume_from_index += 1
        
        logger.info(f"ä»æ­¥éª¤ {resume_from_index} å¼€å§‹æ¢å¤")
        
        # 5. ä»æ–­ç‚¹ç»§ç»­æ‰§è¡Œ
        try:
            for i in range(resume_from_index, len(self.steps)):
                step = self.steps[i]
                
                # æ£€æŸ¥ should_stop æ ‡å¿—
                # ç”¨äºå¤„ç†å·¥ä½œæµæå‰ç»ˆæ­¢çš„æƒ…å†µï¼ˆå¦‚æ‰‹åŠ¨æŸ¥è¯¢æ— ç»“æœï¼‰
                if self.context.get("should_stop", False):
                    # [ä¿®å¤] è°ƒç”¨ç»Ÿä¸€çš„å¤„ç†æ–¹æ³•ï¼Œç¡®ä¿ä¸ run() è¡Œä¸ºä¸€è‡´
                    self._handle_should_stop()
                    return self.execution_id
                
                self._execute_step_with_retry(step, i)
            
            # æ‰€æœ‰æ­¥éª¤å®Œæˆ
            self._update_execution_status("completed", completed_at=datetime.now().isoformat())
            logger.info(f"âœ… å·¥ä½œæµæ¢å¤å¹¶æ‰§è¡Œå®Œæˆ: {self.execution_id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ¢å¤æ‰§è¡Œå¤±è´¥: {e}")
            self._update_execution_status("failed", error=str(e))
            raise e
    
    def _execute_step_with_retry(self, step: WorkflowStep, step_index: int):
        """
        æ‰§è¡Œå•ä¸ªæ­¥éª¤ï¼ˆå«é‡è¯•é€»è¾‘ï¼‰ã€‚
        """
        step_record_id = self._get_step_record_id(step.name)
        
        
        # [ä¼˜åŒ–] å®šä¹‰è¿›åº¦å›è°ƒï¼ˆå«èŠ‚æµé€»è¾‘ï¼‰
        # èŠ‚æµçŠ¶æ€ï¼šè®°å½•ä¸Šæ¬¡å†™å…¥çš„ current å€¼ï¼Œé¿å…æ¯æ¬¡å›è°ƒéƒ½å†™æ•°æ®åº“
        last_update = {"current": 0}
        
        def progress_callback(progress_data: Dict[str, Any]):
            """
            è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°ï¼ˆå«èŠ‚æµé€»è¾‘ï¼‰ã€‚
            
            åŠŸèƒ½ï¼š
                1. æ¥æ”¶æ­¥éª¤çš„è¿›åº¦æ•°æ®
                2. ä½¿ç”¨èŠ‚æµç­–ç•¥å‡å°‘æ•°æ®åº“å†™å…¥é¢‘ç‡
                3. ç¡®ä¿å…³é”®è¿›åº¦ç‚¹ï¼ˆé¦–æ¬¡ã€æ¯5æ¬¡ã€æœ€åä¸€æ¬¡ï¼‰å¿…å®šå†™å…¥
            
            Args:
                progress_data (Dict[str, Any]): è¿›åº¦æ•°æ®ï¼ŒåŒ…å« current, total, message ç­‰å­—æ®µ
            
            èŠ‚æµç­–ç•¥ï¼š
                - ç¬¬1æ¬¡è¿›åº¦ï¼šå¿…å®šå†™å…¥ï¼ˆæ˜¾ç¤ºåˆå§‹çŠ¶æ€ï¼‰
                - æ¯5æ¬¡è¿›åº¦ï¼šå†™å…¥ä¸€æ¬¡ï¼ˆå¦‚ 5, 10, 15...ï¼‰
                - æœ€åä¸€æ¬¡ï¼šå¿…å®šå†™å…¥ï¼ˆæ˜¾ç¤º100%å®Œæˆï¼‰
            """
            try:
                current = progress_data.get("current", 0)
                total = progress_data.get("total", 1)
                
                # èŠ‚æµæ¡ä»¶åˆ¤æ–­
                # 1. æ¯5ç¯‡è®ºæ–‡æ›´æ–°ä¸€æ¬¡ï¼ˆå‡å°‘å†™å…¥é¢‘ç‡ï¼‰
                # 2. ç¬¬1ç¯‡å¿…é¡»æ›´æ–°ï¼ˆæ˜¾ç¤ºåˆå§‹è¿›åº¦ï¼‰
                # 3. æœ€åä¸€ç¯‡å¿…é¡»æ›´æ–°ï¼ˆæ˜¾ç¤º100%å®Œæˆï¼‰
                should_update = (
                    (current - last_update["current"]) >= 5 or  # æ¡ä»¶1ï¼šé—´éš”5ç¯‡
                    current == 1 or                              # æ¡ä»¶2ï¼šç¬¬ä¸€ç¯‡
                    current == total                             # æ¡ä»¶3ï¼šæœ€åä¸€ç¯‡
                )
                
                if should_update:
                    self.db.table("workflow_steps").update({
                        "progress": progress_data
                    }).eq("id", step_record_id).execute()
                    last_update["current"] = current
                    
            except Exception as e:
                logger.error(f"æ›´æ–°æ­¥éª¤è¿›åº¦å¤±è´¥: {e}")
        
        # æ³¨å…¥å›è°ƒ
        step.set_progress_callback(progress_callback)
        
        # max_retries æ˜¯é‡è¯•æ¬¡æ•°ï¼Œæ‰€ä»¥æ€»å°è¯•æ¬¡æ•°æ˜¯ max_retries + 1
        total_attempts = step.max_retries + 1
        
        for attempt in range(1, total_attempts + 1):
            try:
                logger.info("\n" + "="*50)
                logger.info(f"ğŸ‘‰ æ‰§è¡Œæ­¥éª¤ [{step.name}] (å°è¯• {attempt}/{total_attempts})...")
                logger.info("="*50)
                
                # æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸º running
                self._update_step_status(step_record_id, "running", retry_count=attempt - 1)
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # æ‰§è¡Œæ­¥éª¤
                result = step.execute(self.context)
                
                # è®°å½•è€—æ—¶
                duration_ms = int((time.time() - start_time) * 1000)
                
                # æ›´æ–°ä¸Šä¸‹æ–‡
                if result:
                    self.context.update(result)
                    # [FIX] æŒä¹…åŒ–ä¸Šä¸‹æ–‡åˆ°æ•°æ®åº“ï¼Œç¡®ä¿æ–­ç‚¹æ¢å¤æ—¶èƒ½è·å–æœ€æ–°çŠ¶æ€
                    self._update_execution_context()
                
                # è®¡ç®—æˆæœ¬
                # ä¼˜å…ˆä½¿ç”¨æ­¥éª¤è¿”å›çš„ç²¾ç¡® Cost (å¦‚æœ API æ”¯æŒ)
                # å¦‚æœæ­¥éª¤æ²¡æœ‰è®¾ç½® cost (ä¸º0)ï¼Œåˆ™æ ¹æ® Token è®¡ç®—
                # æ³¨æ„: æŸäº›æ­¥éª¤å¯èƒ½å·²ç»è®¾ç½®äº† cost (å¦‚ paper_service è¿”å›çš„)
                step_cost = step.cost
                
                # è·å–é¢å¤–æŒ‡æ ‡
                cache_hit = step.metrics.get("cache_hit_tokens", 0)
                request_count = step.metrics.get("request_count", 0)
                model_name = step.metrics.get("model_name", "")
                
                # å¦‚æœæ²¡æœ‰ç²¾ç¡® Costï¼Œæ‰‹åŠ¨è®¡ç®—
                if step_cost == 0.0 and (step.tokens_input > 0 or step.tokens_output > 0):
                    # æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©å®šä»·
                    price_input = self.llm_price_input
                    price_output = self.llm_price_output
                    
                    if "qwen-plus" in model_name:
                        price_input = settings.QWEN_PLUS_PRICE_INPUT
                        price_output = settings.QWEN_PLUS_PRICE_OUTPUT
                    elif "qwen3-max" in model_name:
                        price_input = settings.QWEN_MAX_PRICE_INPUT
                        price_output = settings.QWEN_MAX_PRICE_OUTPUT
                    
                    step_cost = (step.tokens_input / 1_000_000) * price_input + \
                                (step.tokens_output / 1_000_000) * price_output
                
                # æ›´æ–°æ­¥éª¤ä¸ºå®Œæˆ
                self._update_step_status(
                    step_record_id, 
                    "completed",
                    duration_ms=duration_ms,
                    tokens_input=step.tokens_input,
                    tokens_output=step.tokens_output,
                    cost=step_cost,
                    completed_at=datetime.now().isoformat(),
                    # æ–°å¢å­—æ®µ
                    model_name=model_name,
                    cache_hit_tokens=cache_hit,
                    request_count=request_count
                )
                
                # ç´¯åŠ åˆ°å·¥ä½œæµæ€»æ¶ˆè€—
                self._increment_workflow_cost(step.tokens_input, step.tokens_output, step_cost)
                
                # æ›´æ–°å½“å‰æ­¥éª¤åç§°
                self._update_current_step(step.name)
                
                logger.info(f"âœ… æ­¥éª¤ [{step.name}] å®Œæˆã€‚è€—æ—¶: {duration_ms}ms, æˆæœ¬: ${step_cost:.6f}")
                
                return  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                
            except Exception as e:
                error_msg = str(e)
                error_stack = traceback.format_exc()
                logger.error(f"âŒ æ­¥éª¤ [{step.name}] æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt}): {error_msg}")
                
                if attempt < total_attempts:
                    # æŒ‡æ•°é€€é¿
                    delay = 2 ** (attempt - 1) * int(os.environ.get("WORKFLOW_RETRY_DELAY_BASE", "2"))
                    logger.info(f"â³ {delay}ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œæ ‡è®°æ­¥éª¤å¤±è´¥
                    self._update_step_status(
                        step_record_id,
                        "failed",
                        error_message=error_msg,
                        error_stack=error_stack
                    )
                    raise e  # æŠ›å‡ºå¼‚å¸¸ï¼Œä¸­æ­¢å·¥ä½œæµ
    
    def _create_execution_record(self, workflow_type: str) -> str:
        """åˆ›å»ºå·¥ä½œæµæ‰§è¡Œè®°å½•"""
        execution_id = str(uuid4())
        data = {
            "id": execution_id,
            "workflow_type": workflow_type,
            "status": "running",
            "total_steps": len(self.steps),
            "completed_steps": 0,
            "metadata": json.dumps(self.context)
        }
        self.db.table("workflow_executions").insert(data).execute()
        return execution_id
    
    def _create_step_record(self, step: WorkflowStep, step_order: int):
        """åˆ›å»ºæ­¥éª¤è®°å½•"""
        data = {
            "execution_id": self.execution_id,
            "step_name": step.name,
            "step_order": step_order,
            "status": "pending",
            "max_retries": step.max_retries
        }
        self.db.table("workflow_steps").insert(data).execute()
    
    def _get_step_record_id(self, step_name: str) -> str:
        """è·å–æ­¥éª¤è®°å½• ID"""
        response = self.db.table("workflow_steps") \
            .select("id") \
            .eq("execution_id", self.execution_id) \
            .eq("step_name", step_name) \
            .execute()
        return response.data[0]["id"]
    
    def _update_step_status(self, step_id: str, status: str, **kwargs):
        """æ›´æ–°æ­¥éª¤çŠ¶æ€"""
        data = {"status": status}
        data.update(kwargs)
        self.db.table("workflow_steps").update(data).eq("id", step_id).execute()
    
    def _handle_should_stop(self) -> None:
        """
        å¤„ç†å·¥ä½œæµæå‰ç»ˆæ­¢çš„ç»Ÿä¸€æ–¹æ³•ã€‚
        
        åŠŸèƒ½ï¼š
        1. ä» context ä¸­æå– stop_reason å’Œ stop_message
        2. è·å–å½“å‰æ‰§è¡Œè®°å½•çš„ metadata å¹¶åˆå¹¶æ–°ä¿¡æ¯
        3. æ›´æ–°æ‰§è¡ŒçŠ¶æ€ä¸º stopped
        
        ä½¿ç”¨åœºæ™¯ï¼š
        - run() æ–¹æ³•ï¼šå¯åŠ¨æ–°å·¥ä½œæµæ—¶é‡åˆ° should_stop
        - resume() æ–¹æ³•ï¼šæ¢å¤å·¥ä½œæµæ—¶é‡åˆ° should_stop
        
        Args:
            æ— ï¼ˆä½¿ç”¨ self.context å’Œ self.execution_idï¼‰
        
        Returns:
            None
        """
        # è·å–åœæ­¢åŸå› å’Œæ¶ˆæ¯
        stop_reason = self.context.get("stop_reason", "unknown")
        stop_message = self.context.get("message", "å·¥ä½œæµå·²åœæ­¢")
        
        logger.info(f"â¸ï¸ å·¥ä½œæµæå‰ç»ˆæ­¢: reason={stop_reason}, message={stop_message}")
        
        # è·å–å½“å‰ metadata å¹¶åˆå¹¶æ–°ä¿¡æ¯
        # åŸå› ï¼šé¿å…è¦†ç›–å·²æœ‰çš„å…¶ä»– metadata å­—æ®µ
        try:
            current_metadata_res = self.db.table("workflow_executions") \
                .select("metadata") \
                .eq("id", self.execution_id) \
                .execute()
            
            current_metadata = {}
            if current_metadata_res.data and current_metadata_res.data[0].get("metadata"):
                current_metadata = json.loads(current_metadata_res.data[0]["metadata"])
        except Exception as e:
            logger.warning(f"è·å–å½“å‰ metadata å¤±è´¥: {e}")
            current_metadata = {}
        
        # åˆå¹¶æ–°çš„åœæ­¢ä¿¡æ¯
        current_metadata.update({
            "stop_reason": stop_reason,
            "stop_message": stop_message
        })
        
        # æ›´æ–°çŠ¶æ€ä¸º stopped
        self._update_execution_status(
            "stopped",
            completed_at=datetime.now().isoformat(),
            metadata=json.dumps(current_metadata)
        )
    
    def _update_execution_status(self, status: str, **kwargs):
        """æ›´æ–°æ‰§è¡Œè®°å½•çŠ¶æ€"""
        data = {"status": status}
        data.update(kwargs)
        self.db.table("workflow_executions").update(data).eq("id", self.execution_id).execute()
    
    def _update_current_step(self, step_name: str):
        """æ›´æ–°å½“å‰æ­¥éª¤"""
        self.db.table("workflow_executions").update({
            "current_step": step_name
        }).eq("id", self.execution_id).execute()
    
    def _calculate_cost(self, tokens_input: int, tokens_output: int) -> float:
        """
        è®¡ç®—æˆæœ¬ (USD)ã€‚
        
        Args:
            tokens_input (int): è¾“å…¥ Token æ•°
            tokens_output (int): è¾“å‡º Token æ•°
        
        Returns:
            float: æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        cost_input = (tokens_input / 1_000_000) * self.llm_price_input
        cost_output = (tokens_output / 1_000_000) * self.llm_price_output
        return cost_input + cost_output
    
    def _increment_workflow_cost(self, tokens_input: int, tokens_output: int, cost: float):
        """ç´¯åŠ å·¥ä½œæµæ€»æˆæœ¬"""
        # è¯»å–å½“å‰å€¼
        response = self.db.table("workflow_executions") \
            .select("total_tokens_input", "total_tokens_output", "total_cost") \
            .eq("id", self.execution_id) \
            .execute()
        
        current = response.data[0]
        
        # ç´¯åŠ 
        new_data = {
            "total_tokens_input": current["total_tokens_input"] + tokens_input,
            "total_tokens_output": current["total_tokens_output"] + tokens_output,
            "total_cost": current["total_cost"] + cost
        }
        
        self.db.table("workflow_executions").update(new_data).eq("id", self.execution_id).execute()
    
    def _increment_completed_steps(self):
        """
        å¢åŠ å·²å®Œæˆæ­¥éª¤è®¡æ•°ã€‚
        
        æ³¨æ„ï¼šè¿™é‡Œçš„å®ç°æ˜¯éåŸå­æ€§çš„ï¼Œå¦‚æœåœ¨å¹¶å‘åœºæ™¯ä¸‹å¯èƒ½æœ‰ç«äº‰æ¡ä»¶ã€‚
        ç†æƒ³æƒ…å†µä¸‹åº”è¯¥ä½¿ç”¨æ•°æ®åº“çš„åŸå­æ“ä½œï¼ˆå¦‚ PostgreSQL çš„ UPDATE ... SET count = count + 1ï¼‰ã€‚
        ä½† Supabase Python å®¢æˆ·ç«¯çš„ RESTful API ä¸ç›´æ¥æ”¯æŒï¼Œéœ€è¦é€šè¿‡ RPC æˆ–åŸç”Ÿ SQLã€‚
        è¿™é‡Œæš‚æ—¶ä¿æŒç®€å•å®ç°ã€‚
        """
        # TODO: å®ç°åŸå­æ€§å¢é‡æ›´æ–°
        pass
    
    def _send_failure_alert(self, workflow_type: str, error: str, stack_trace: str):
        """
        å‘é€å¤±è´¥å‘Šè­¦é‚®ä»¶ã€‚
        
        Args:
            workflow_type (str): å·¥ä½œæµç±»å‹
            error (str): é”™è¯¯ä¿¡æ¯
            stack_trace (str): å †æ ˆè·Ÿè¸ª
        """
        subject = f"âŒ å·¥ä½œæµå¤±è´¥å‘Šè­¦: {workflow_type}"
        content = f"""
å·¥ä½œæµæ‰§è¡Œå¤±è´¥

æ‰§è¡Œ ID: {self.execution_id}
å·¥ä½œæµç±»å‹: {workflow_type}
å¤±è´¥æ—¶é—´: {datetime.now()}
é”™è¯¯ä¿¡æ¯: {error}

å †æ ˆè·Ÿè¸ª:
{stack_trace}
        """
        # TODO: è°ƒç”¨ email_service.send_email(self.admin_emails, subject, content)
        logger.info(f"ğŸ“§ å·²å‘é€å¤±è´¥å‘Šè­¦é‚®ä»¶ç»™: {self.admin_emails}")

    def _update_execution_context(self):
        """æ›´æ–°æ‰§è¡Œè®°å½•çš„ä¸Šä¸‹æ–‡å…ƒæ•°æ®ã€‚"""
        if not self.execution_id:
            return
        try:
            self.db.table("workflow_executions").update({
                "metadata": json.dumps(self.context)
            }).eq("id", self.execution_id).execute()
        except Exception as e:
            logger.error(f"æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡å¤±è´¥: {e}")

    def generate_summary_report(self):
        """
        ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œæ±‡æ€»æŠ¥å‘Š (è¡¨æ ¼å½¢å¼)ã€‚
        åŒ…å«: é˜¶æ®µå | Model | Cost | Input | Output | Cache Hit | Requests | Time
        """
        try:
            print("\n" + "="*120)
            print(f"ğŸ“Š å·¥ä½œæµæ‰§è¡Œæ±‡æ€»æŠ¥å‘Š (ID: {self.execution_id})")
            print("="*120)
             
            # è·å–æ‰€æœ‰æ­¥éª¤è®°å½•
            response = self.db.table("workflow_steps") \
                .select("*") \
                .eq("execution_id", self.execution_id) \
                .order("step_order") \
                .execute()
            
            steps = response.data
            
            # è¡¨å¤´
            header = f"{'é˜¶æ®µå':<22} | {'Model':<15} | {'Cost ($)':<10} | {'Input':<8} | {'Output':<8} | {'Cache':<8} | {'Reqs':<5} | {'Time':<10}"
            print(header)
            print("-" * len(header))
            
            total_cost = 0.0
            total_input = 0
            total_output = 0
            total_cache = 0
            total_reqs = 0
            total_duration_ms = 0
            
            for s in steps:
                name = s.get("step_name", "")
                model = s.get("model_name") or "-"
                cost = s.get("cost", 0.0)
                inp = s.get("tokens_input", 0)
                out = s.get("tokens_output", 0)
                cache = s.get("cache_hit_tokens", 0)
                reqs = s.get("request_count", 0)
                duration_ms = s.get("duration_ms", 0) or 0
                
                # æ ¼å¼åŒ–æ—¶é—´
                duration_sec = duration_ms / 1000
                if duration_sec > 60:
                    minutes = int(duration_sec // 60)
                    seconds = int(duration_sec % 60)
                    time_str = f"{minutes}m {seconds}s"
                else:
                    time_str = f"{duration_sec:.2f}s"
                
                # ç´¯åŠ 
                total_cost += cost
                total_input += inp
                total_output += out
                total_cache += cache
                total_reqs += reqs
                total_duration_ms += duration_ms
                
                print(f"{name:<25} | {model:<15} | {cost:<10.6f} | {inp:<8} | {out:<8} | {cache:<8} | {reqs:<5} | {time_str:<10}")
            
            # æ ¼å¼åŒ–æ€»æ—¶é—´
            total_duration_sec = total_duration_ms / 1000
            if total_duration_sec > 60:
                total_minutes = int(total_duration_sec // 60)
                total_seconds = int(total_duration_sec % 60)
                total_time_str = f"{total_minutes}m {total_seconds}s"
            else:
                total_time_str = f"{total_duration_sec:.2f}s"

            print("-" * len(header))
            print(f"{'TOTAL':<25} | {'-':<15} | {total_cost:<10.6f} | {total_input:<8} | {total_output:<8} | {total_cache:<8} | {total_reqs:<5} | {total_time_str:<10}")
            print("="*95 + "\n")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
