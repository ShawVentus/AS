"""
ç»å°”APIè¿ç§»æµ‹è¯•è„šæœ¬

ä¸»è¦åŠŸèƒ½ï¼š
    1. éªŒè¯ç»å°”APIè¿æ¥æ˜¯å¦æ­£å¸¸
    2. éªŒè¯æˆæœ¬è®¡ç®—é€»è¾‘çš„å‡†ç¡®æ€§
    3. æµ‹è¯•å¤šProvideråˆ‡æ¢åŠŸèƒ½
    4. ä½¿ç”¨çœŸå®åœºæ™¯æµ‹è¯•è®ºæ–‡ç­›é€‰åŠŸèƒ½

æµ‹è¯•æ—¥æœŸï¼š2025-12-16
"""

import os
import sys
from pathlib import Path

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_dir))

from app.core.config import settings
from app.services.llm_service import llm_service

def test_bohrium_connection():
    """
    æµ‹è¯•1ï¼šéªŒè¯ç»å°”APIè¿æ¥
    
    åŠŸèƒ½è¯´æ˜ï¼š
        å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚åˆ°ç»å°”APIï¼Œæ£€æŸ¥å“åº”æ˜¯å¦æ­£å¸¸ã€‚
        éªŒè¯tokenç»Ÿè®¡å’Œæˆæœ¬è®¡ç®—æ˜¯å¦æ­£ç¡®è¿”å›ã€‚
    """
    print("=" * 60)
    print("æµ‹è¯•1ï¼šç»å°”APIè¿æ¥æµ‹è¯•")
    print("=" * 60)
    
    # ç¡®ä¿ä½¿ç”¨bohrium provider
    original_provider = settings.LLM_PROVIDER
    os.environ["LLM_PROVIDER"] = "bohrium"
    settings.LLM_PROVIDER = "bohrium"
    
    try:
        # é‡æ–°åˆå§‹åŒ–æœåŠ¡
        from app.services.llm_service import QwenService
        test_service = QwenService()
        
        # ç®€å•çš„æµ‹è¯•prompt
        test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        
        response, usage = test_service.call_llm(
            test_prompt, 
            model="qwen-plus",
            response_format=None
        )
        
        print(f"âœ… è¯·æ±‚æˆåŠŸ")
        print(f"ğŸ“Š å“åº”å†…å®¹: {response[:100]}...")
        print(f"ğŸ“ˆ Tokenç»Ÿè®¡:")
        print(f"   - è¾“å…¥tokens: {usage.get('prompt_tokens', 0)}")
        print(f"   - è¾“å‡ºtokens: {usage.get('completion_tokens', 0)}")
        print(f"   - æ€»tokens: {usage.get('total_tokens', 0)}")
        print(f"   - ç¼“å­˜å‘½ä¸­tokens: {usage.get('cache_hit_tokens', 0)}")
        print(f"   - æˆæœ¬: ${usage.get('cost', 0):.6f}")
        print(f"   - æ¨¡å‹: {usage.get('model', 'N/A')}")
        
        # éªŒè¯å¿…è¦å­—æ®µ
        assert usage.get('prompt_tokens', 0) > 0, "prompt_tokensåº”è¯¥å¤§äº0"
        assert usage.get('completion_tokens', 0) > 0, "completion_tokensåº”è¯¥å¤§äº0"
        assert usage.get('cost', 0) > 0, "æˆæœ¬åº”è¯¥å·²è®¡ç®—"
        
        print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¢å¤åŸå§‹é…ç½®
        os.environ["LLM_PROVIDER"] = original_provider
        settings.LLM_PROVIDER = original_provider

def test_cost_calculation():
    """
    æµ‹è¯•2ï¼šéªŒè¯æˆæœ¬è®¡ç®—å‡†ç¡®æ€§
    
    åŠŸèƒ½è¯´æ˜ï¼š
        ä½¿ç”¨å·²çŸ¥tokenæ•°é‡çš„è¯·æ±‚ï¼ŒéªŒè¯è‡ªåŠ¨æˆæœ¬è®¡ç®—å…¬å¼æ˜¯å¦æ­£ç¡®ã€‚
        å¯¹æ¯”æ‰‹åŠ¨è®¡ç®—å’Œè‡ªåŠ¨è®¡ç®—çš„æˆæœ¬ï¼Œç¡®ä¿è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯•2ï¼šæˆæœ¬è®¡ç®—å‡†ç¡®æ€§éªŒè¯")
    print("=" * 60)
    
    os.environ["LLM_PROVIDER"] = "bohrium"
    settings.LLM_PROVIDER = "bohrium"
    
    try:
        from app.services.llm_service import QwenService
        test_service = QwenService()
        
        # ä½¿ç”¨å›ºå®šå†…å®¹çš„prompt
        test_prompt = "1+1ç­‰äºå‡ ï¼Ÿè¯·åªå›ç­”æ•°å­—ã€‚"
        
        response, usage = test_service.call_llm(
            test_prompt,
            model="qwen-plus",
            response_format=None
        )
        
        # è·å–å®šä»·
        pricing = settings.get_model_pricing("qwen-plus")
        
        # æ‰‹åŠ¨è®¡ç®—æˆæœ¬
        manual_input_cost = (usage['prompt_tokens'] / 1_000_000) * pricing['input_price']
        manual_output_cost = (usage['completion_tokens'] / 1_000_000) * pricing['output_price']
        manual_total_cost = manual_input_cost + manual_output_cost
        
        # è‡ªåŠ¨è®¡ç®—çš„æˆæœ¬
        auto_cost = usage.get('cost', 0)
        
        print(f"ğŸ“Š Tokenç»Ÿè®¡:")
        print(f"   - è¾“å…¥: {usage['prompt_tokens']} tokens")
        print(f"   - è¾“å‡º: {usage['completion_tokens']} tokens")
        print(f"\nğŸ’° æˆæœ¬è®¡ç®—:")
        print(f"   - è¾“å…¥ä»·æ ¼: ${pricing['input_price']}/1M tokens")
        print(f"   - è¾“å‡ºä»·æ ¼: ${pricing['output_price']}/1M tokens")
        print(f"   - æ‰‹åŠ¨è®¡ç®—: ${manual_total_cost:.8f}")
        print(f"   - è‡ªåŠ¨è®¡ç®—: ${auto_cost:.8f}")
        print(f"   - å·®å¼‚: ${abs(manual_total_cost - auto_cost):.8f}")
        
        # å…è®¸å¾®å°çš„æµ®ç‚¹è¯¯å·®
        assert abs(manual_total_cost - auto_cost) < 0.000001, "æˆæœ¬è®¡ç®—å·®å¼‚è¿‡å¤§"
        
        print("âœ… æˆæœ¬è®¡ç®—å‡†ç¡®")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_provider_switching():
    """
    æµ‹è¯•3ï¼šéªŒè¯å¤šProvideråˆ‡æ¢åŠŸèƒ½
    
    åŠŸèƒ½è¯´æ˜ï¼š
        æµ‹è¯•åœ¨bohriumã€openrouterã€dashscopeä¹‹é—´åˆ‡æ¢ã€‚
        éªŒè¯æ¯ä¸ªå·²é…ç½®API Keyçš„Provideréƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯•3ï¼šå¤šProvideråˆ‡æ¢åŠŸèƒ½")
    print("=" * 60)
    
    providers = ["bohrium", "openrouter", "dashscope"]
    results = {}
    
    for provider in providers:
        print(f"\nğŸ”„ æµ‹è¯•Provider: {provider}")
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†API key
        os.environ["LLM_PROVIDER"] = provider
        settings.LLM_PROVIDER = provider
        
        try:
            config = settings.get_llm_config()
            if not config["api_key"]:
                print(f"âš ï¸  {provider} æœªé…ç½®API Keyï¼Œè·³è¿‡")
                results[provider] = "æœªé…ç½®"
                continue
                
            from app.services.llm_service import QwenService
            test_service = QwenService()
            
            response, usage = test_service.call_llm(
                "ä½ å¥½",
                model="qwen-plus",
                response_format=None
            )
            
            print(f"âœ… {provider} å·¥ä½œæ­£å¸¸")
            print(f"   - Tokens: {usage.get('total_tokens', 0)}")
            print(f"   - æˆæœ¬: ${usage.get('cost', 0):.6f}")
            results[provider] = "æˆåŠŸ"
            
        except Exception as e:
            print(f"âŒ {provider} å¤±è´¥: {e}")
            results[provider] = f"å¤±è´¥: {str(e)[:50]}"
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    for provider, status in results.items():
        print(f"  {provider}: {status}")

def test_paper_filter():
    """
    æµ‹è¯•4ï¼šå®é™…workflowæµ‹è¯• - è®ºæ–‡ç­›é€‰
    
    åŠŸèƒ½è¯´æ˜ï¼š
        ä½¿ç”¨çœŸå®çš„è®ºæ–‡æ•°æ®æµ‹è¯•filter_paperåŠŸèƒ½ã€‚
        éªŒè¯æˆæœ¬ç»Ÿè®¡æ˜¯å¦æ­£ç¡®è®°å½•åœ¨è¿”å›ç»“æœä¸­ã€‚
    """
    print("\n" + "=" * 60)
    print("æµ‹è¯•4ï¼šè®ºæ–‡ç­›é€‰åŠŸèƒ½ï¼ˆå®é™…åœºæ™¯ï¼‰")
    print("=" * 60)
    
    os.environ["LLM_PROVIDER"] = "bohrium"
    settings.LLM_PROVIDER = "bohrium"
    
    try:
        from app.services.llm_service import QwenService
        test_service = QwenService()
        
        # æ¨¡æ‹Ÿè®ºæ–‡æ•°æ®
        test_paper = {
            "title": "Attention Is All You Need",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...",
            "category": "cs.CL"
        }
        
        test_profile = "ç ”ç©¶è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«å…³æ³¨Transformeræ¶æ„"
        
        result = test_service.filter_paper(test_paper, test_profile)
        
        print(f"âœ… ç­›é€‰å®Œæˆ")
        print(f"ğŸ“Š ç»“æœ:")
        print(f"   - ç›¸å…³æ€§: {result.get('is_relevant', False)}")
        print(f"   - è¯„åˆ†: {result.get('score', 0)}/10")
        print(f"   - ç†ç”±: {result.get('reason', 'N/A')[:100]}...")
        print(f"ğŸ’° æˆæœ¬ç»Ÿè®¡:")
        usage = result.get('_usage', {})
        print(f"   - è¾“å…¥tokens: {usage.get('prompt_tokens', 0)}")
        print(f"   - è¾“å‡ºtokens: {usage.get('completion_tokens', 0)}")
        print(f"   - æˆæœ¬: ${usage.get('cost', 0):.6f}")
        
        assert '_usage' in result, "ç»“æœåº”åŒ…å«_usageå­—æ®µ"
        assert usage.get('cost', 0) > 0, "æˆæœ¬åº”å·²è®¡ç®—"
        
        print("âœ… æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ç»å°”APIè¿ç§»æµ‹è¯•\n")
    
    # ä¿å­˜åŸå§‹é…ç½®
    original_provider = settings.LLM_PROVIDER
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_bohrium_connection()
        test_cost_calculation()
        test_provider_switching()
        test_paper_filter()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("=" * 60)
        
    finally:
        # æ¢å¤åŸå§‹é…ç½®
        os.environ["LLM_PROVIDER"] = original_provider
        settings.LLM_PROVIDER = original_provider
